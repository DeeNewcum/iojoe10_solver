- TODO: study this:
        https://en.wikipedia.org/wiki/Optimal_substructure
          https://en.wikipedia.org/wiki/Dynamic_programming


- IsUnsolvabe::noclipping() is consuming a large percentage of the CPU time.  For instance:
  Letters-4-inverse takes 0.05sec TOTAL in noclipping(), while 
  Letters-4 takes MUCH MUCH longer  (use  --noclipping-verbose on it)

            call #1 to IsUnsolvable::noclipping() took 23,965 ms              and 33,007 subcalls and returned 'solvable'
            call #2 to IsUnsolvable::noclipping() took 6,803 ms                and 6,082 subcalls and returned 'solvable'
            call #3 to IsUnsolvable::noclipping() took 0 ms                       and 12 subcalls and returned 'solvable'
            call #4 to IsUnsolvable::noclipping() took 1,728,828 ms          and 788,446 subcalls and returned 'unsolvable'
            call #5 to IsUnsolvable::noclipping() took 865,275 ms            and 328,716 subcalls and returned 'unsolvable'
            call #6 to IsUnsolvable::noclipping() took 1 ms                       and 10 subcalls and returned 'solvable'
            call #7 to IsUnsolvable::noclipping() took 88,864 ms              and 24,905 subcalls and returned 'unsolvable'
            call #8 to IsUnsolvable::noclipping() took 129,191 ms             and 47,673 subcalls and returned 'unsolvable'
            call #9 to IsUnsolvable::noclipping() took 72,380 ms              and 22,476 subcalls and returned 'unsolvable'

  Some possible solutions to try to reduce this:

        - Try to pre-calculate the results for IsUnsolvabe::noclipping(), for all solutions less
          than N pieces.  Find out if it can be stored using sparse matrix techniques, since this
          could help reduce the exponential nature of the problem.

        - Try storing the memoize cache on disk, see if that helps.

        - [unfocused]  When I solve games, as a human, I put off doing noclipping() calculations until near the
          end of the board.  Is it possible to implement something like that here?
          However, humans are able to identify specific pieces as "probably valuable", and when
          doing the search, focus on resolving that piece before moving on to other pieces.
          I don't really understand this process though.

        - [unfocused]  It looks like it's the 'unsolvable' calls that are taking the longest.
          Is there any way to combine the two graph-search problems into one, so after so much time
          spent examining things in one direction, we decide it's a better use of our time to
          examine in another direction?


- add more test cases for IsUnsolvable::islands()
            Development was done EXTREMELY quickly, and it's possible (likely?) that there are one
            or two bugs that were never properly examined.


- [TEST-CORE] improve coverage of the Core routines

    - In move_apply.t, change ok_move() to feed its data through Board::new_from_string().  This
      allows us to avoid this whole crap about separate variables for pieces, and generally makes it
      much more readable.

- [TEST-CORE] add the ability to test for specific combined-groups

    - add new functionality to --yardstick:
            - have it find *all* possible solutions that have the same (optimal) depth
            - compare all of those solutions, find all common combined-groups, and report those

- Use a stochastic rather than deterministic algorithm for IsUnsolvable::no_clipping.  Basically
  incorporate it into the heuristic function, so that we prioritize searching the nodes that seem
  most promising.
                  (I think this is called an "anytime algorithm"?)

       >> In particular, this means that we don't have to spend the huge amount of CPU that
          is required to determine that a piece-list is *unsolvable*.  Determining that a piece-list
          is solvable can take MUCH less CPU, compared to determining that it's unsolvable.  So put
          a CPU-limit on our evaluator, and if we come up with a few answers that say "yes, it's
          solvable", then preferentially explore those.


- Add more tests for IsUnsolvable::no_clipping(), and clear the Memoize cache in between tests.
  This routine has recently gotten more complicated, and I'm not 100% confident that the new design
  will always produce correct results.                  (Memorize::flush_cache('IsUnsolvable::_noclipping'))


- This points out that A* can be FAST or ACCURATE but not both.
        http://theory.stanford.edu/~amitp/GameProgramming/Heuristics.html#speed-or-accuracy
  Because of my dogged pursuit of speed, it's likely I will end up compromising accuracy.
  Therefore, I need metrics that show exactly how much accuracy is compromised, to make sure
  I don't overdo it.  The "shortest_solution" will be used to monitor this.


- Add a --relax cmdline parameter, as mentioned here:
        http://theory.stanford.edu/~amitp/GameProgramming/Heuristics.html#speed-or-accuracy
        https://en.wikipedia.org/wiki/A*_search_algorithm#Bounded_relaxation



- Are there any ways to improve the heuristic?  That seems like one of the best ways to speed up A*.

        - have it prioritize combining  9s and 8s (and maybe 1s?) over other combinations

        - Is there any way to extract the data when IsUnsolvable::noclipping_mark3 knows FOR SURE
          that two or more blocks need to combine eventually?  If so, we should *absolutely*
          prioritize those before any other moves.


- Are there any ways to improve the algorithm, other than the heuristic?

        - Is there any way to apply Jump Point Search to "10"?
          What if we 1) *imagined* that we could move pieces around, without being 100% confident
          that we could, 2) explored whether that gets us closer to the destination, and 
          3) if it DOES get us closer to the destination, then we go back and double-check that
          the mental leap taken in Step #1 is actually possible?
                  http://harablog.wordpress.com/2011/09/07/jump-point-search/


- add more boards


- possible constant-time optimizations:

    - install Class::XSAccessor   (Moo says it can speed things up if this is installed)


- release to a few people:

    - contact the author, see if they're interested in this at all
            (it's very possible they have already built their own)

                https://twitter.com/10TheGame
                https://twitter.com/iojoetweets
                http://www.iojoe.com/about.html     simon @ iojoe.com


    - post in some other places:
                http://jayisgames.com/archives/2013/10/10.php



- Create a new series of boards for inclusion with the game, called "10 is Routing".
  The emphasis here is on path-finding / routing pieces through a path, and providing little
  structures that allow 1) pieces to exchange positions, 2) T-branches so they can go one way or the
  other, etc.

  The board Hard-13 is a great example of this kind of board.  However, it is a bit hard, and there
  should be a ramp-up in difficulty, levels that are a little less hard, for the player to learn
  from.


- Compress the solution listing...  make it wider.
  Use Term::Readkey?   http://stackoverflow.com/a/1782149/1042525
  Or just assume it's 80 cols wide, in which case we can fit 5 boards wide...


- The "number of moves" metric is incorrect at the very beginning of a large board.  A* actually
  evaluates ALL first-level moves, always, up-front.  It looks like the current metric only counts
  moves after we pull them off of the open set.  We should change this so it counts moves AS they're
  being put onto the open set.


- Notes about time-per-move in A* versus IDDFS:
  A* seems to take more time-per-move than IDDFS.  I'm not sure this is a fair comparison, however.
  IDDFS visits nodes several times, and there are several caching mechanisms in the algorithm.
  These caches will make IDDFS appear to be faster (per-move) than A*, but this is an illusion.

        - If the IDDFS metric is inaccurate, then we haven't been getting proper information about
          how much of a time-penalty we get from fingerprinting or other "optional" features.
          TODO: Re-evaluate these on A* instead.


- notes from implementing A*:

    "A* search is one of the best general-purpose graph search algorithms when there's a way to
    estimate the distance to the goal"

    http://www.cs.ualberta.ca/~tony/RecentPapers/Draft.5.2.pdf
    http://www.autonlab.org/tutorials/astar08.pdf
    http://www.gamasutra.com/view/feature/131724/smart_move_intelligent_.php?page=5
    https://en.wikibooks.org/wiki/Artificial_Intelligence/Search/Heuristic_search/Astar_Search
    http://www.youtube.com/playlist?list=PL473C810C4140E164
    http://heyes-jones.com/astar.php
    http://www.gamasutra.com/view/feature/131505/toward_more_realistic_pathfinding.php?print=1

    articles with pseudocode, or have discussions of implementation details:
        https://en.wikipedia.org/wiki/A*_search_algorithm#Pseudocode
        http://www.policyalmanac.org/games/aStarTutorial.htm
        http://web.mit.edu/eranki/www/tutorials/search/
        http://theory.stanford.edu/~amitp/GameProgramming/ImplementationNotes.html
        http://wiki.gamegardens.com/Path_Finding_Tutorial#Pseudo-code_A.2A

    advice on optimizing A*, making it FASTER
        http://www.seas.upenn.edu/~cis568/presentations/AStar.pdf
        http://harablog.wordpress.com/2011/09/07/jump-point-search/

